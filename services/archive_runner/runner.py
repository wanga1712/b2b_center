"""
–û—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥—É–ª—å –∑–∞–ø—É—Å–∫–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Ç–æ—Ä–≥–æ–≤.
"""

from __future__ import annotations

import os
import time
import shutil
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple
from concurrent.futures import ThreadPoolExecutor, as_completed

from loguru import logger

from config.settings import config
from core.database import DatabaseManager
from core.tender_database import TenderDatabaseManager
from core.exceptions import DocumentSearchError, DatabaseConnectionError
from services.document_search_service import DocumentSearchService
from services.document_search.document_selector import DocumentSelector
from services.document_search.document_downloader import DocumentDownloader
from services.document_search.archive_extractor import ArchiveExtractor
from services.document_search.match_finder import MatchFinder
from services.tender_repository import TenderRepository
from services.tender_match_repository import TenderMatchRepository
from services.archive_runner.file_cleaner import FileCleaner
from services.archive_runner.existing_files_processor import ExistingFilesProcessor
from services.archive_runner.tender_provider import TenderProvider


class ArchiveBackgroundRunner:
    """
    –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä —Ñ–æ–Ω–æ–≤–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:
    1. –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —É–∂–µ —Å–∫–∞—á–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã
    2. –°–∫–∞—á–∏–≤–∞–µ—Ç –Ω–æ–≤—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    3. –ù–∞—Ö–æ–¥–∏—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    """

    ARCHIVE_EXTENSIONS = {".rar", ".zip", ".7z"}
    EXCEL_EXTENSIONS = {".xlsx", ".xls"}

    def __init__(
        self,
        tender_db_manager: TenderDatabaseManager,
        product_db_manager: DatabaseManager,
        user_id: int = 1,
        max_workers: int = 8,
    ):
        self.tender_db_manager = tender_db_manager
        self.product_db_manager = product_db_manager
        self.user_id = user_id
        self.max_workers = max_workers

        self.tender_repo = TenderRepository(tender_db_manager)
        self.tender_match_repo = TenderMatchRepository(tender_db_manager)
        self.tender_provider = TenderProvider(self.tender_repo, user_id)

        download_dir = Path(config.document_download_dir) if config.document_download_dir else Path.home() / "Downloads" / "–ï–ò–°_–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è"
        self.download_dir = download_dir
        self.download_dir.mkdir(parents=True, exist_ok=True)

        self.document_search_service = DocumentSearchService(
            product_db_manager,
            download_dir,
            unrar_path=config.unrar_tool,
            winrar_path=config.winrar_path,
        )
        self.document_search_service.ensure_products_loaded()

        self.selector = DocumentSelector()
        self.downloader = DocumentDownloader(download_dir, progress_callback=None)
        self.extractor = ArchiveExtractor(
            unrar_path=config.unrar_tool,
            winrar_path=config.winrar_path,
        )
        self.match_finder = MatchFinder(self.document_search_service._product_names)
        self.file_cleaner = FileCleaner()
        self.existing_processor = ExistingFilesProcessor(download_dir)

        self._processed_tenders: Set[Tuple[int, str]] = set()
        self._reconnect_delay = 60

    def run(self, specific_tender_ids: Optional[List[Dict[str, Any]]] = None, registry_type: Optional[str] = None) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫ –ø–æ–ª–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏:
        - —Å–Ω–∞—á–∞–ª–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ñ–∞–π–ª—ã
        - –∑–∞—Ç–µ–º –Ω–æ–≤—ã–µ —Ç–æ—Ä–≥–∏ –∏–∑ –ë–î –∏–ª–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–∞–∫—É–ø–∫–∏
        
        Args:
            specific_tender_ids: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –∫–ª—é—á–∞–º–∏ 'id' –∏ 'registry_type' –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∑–∞–∫—É–ø–æ–∫
            registry_type: –¢–∏–ø —Ä–µ–µ—Å—Ç—Ä–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ ('44fz' –∏–ª–∏ '223fz'). –ï—Å–ª–∏ None, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—é—Ç—Å—è –æ–±–∞.
        """
        logger.info("üöÄ –ó–∞–ø—É—Å–∫ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ —Ç–æ—Ä–≥–æ–≤")
        logger.info("=" * 80)

        overall_start = time.time()
        existing_processed = self._process_existing_folders(registry_type=registry_type)

        # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–∞–∫—É–ø–∫–∏, –∏—Å–ø–æ–ª—å–∑—É–µ–º –∏—Ö, –∏–Ω–∞—á–µ –ø–æ–ª—É—á–∞–µ–º –ø–æ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º
        if specific_tender_ids:
            tenders = self._safe_tender_call(
                self.tender_provider.get_target_tenders,
                specific_tender_ids=specific_tender_ids,
                registry_type=registry_type
            )
        else:
            tenders = self._safe_tender_call(
                self.tender_provider.get_target_tenders,
                registry_type=registry_type
            )
        
        if not tenders:
            logger.warning("–ù–µ—Ç —Ç–æ—Ä–≥–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")

        processed = 0
        errors = 0
        total_matches = 0

        for tender in tenders:
            tender_id = tender.get("id")
            registry_type = tender.get("registry_type", "44fz")
            key = (tender_id, registry_type)
            if key in self._processed_tenders:
                logger.info(f"–¢–æ—Ä–≥ {tender_id} ({registry_type}) —É–∂–µ –±—ã–ª –æ–±—Ä–∞–±–æ—Ç–∞–Ω, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                continue

            result = self._process_tender(tender)
            if result:
                processed += 1
                total_matches += result.get("match_count", 0)
                self._processed_tenders.add(key)
            else:
                errors += 1

        overall_time = time.time() - overall_start

        logger.info(f"\n{'='*80}")
        logger.info("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        logger.info(f"{'='*80}")
        logger.info(f"üìÅ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π: {existing_processed}")
        logger.info(f"üì¶ –ù–æ–≤—ã—Ö —Ç–æ—Ä–≥–æ–≤: {len(tenders)}")
        logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {processed}")
        logger.info(f"‚ùå –û—à–∏–±–æ–∫: {errors}")
        logger.info(f"üîç –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {total_matches}")
        logger.info(f"‚è±Ô∏è  –û–±—â–µ–µ –≤—Ä–µ–º—è: {overall_time:.2f} —Å–µ–∫")

        return {
            "existing_processed": existing_processed,
            "total_tenders": len(tenders),
            "processed": processed,
            "errors": errors,
            "total_matches": total_matches,
            "total_time": overall_time,
        }

    def _process_existing_folders(self, registry_type: Optional[str] = None) -> int:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —É–∂–µ —Å–∫–∞—á–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è—Ö."""
        entries = self.existing_processor.list_pending_tenders()
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Ñ–∞–π–ª–∞–º–∏: {len(entries)}")
        processed = 0
        for entry in entries:
            if registry_type and entry.get("registry_type") != registry_type:
                continue
            tender = {
                "id": entry["tender_id"],
                "registry_type": entry["registry_type"],
                "folder_path": entry["folder_path"],
            }
            documents = self._safe_tender_call(
                self.tender_provider.get_tender_documents,
                tender["id"],
                tender["registry_type"],
            )
            existing_records = self.existing_processor.build_records(entry["folder_path"])
            if not existing_records:
                continue
            result = self._process_tender(
                tender,
                documents=documents,
                existing_records=existing_records,
            )
            if result:
                processed += 1
                self._processed_tenders.add((tender["id"], tender["registry_type"]))
        return processed

    def _process_tender(
        self,
        tender: Dict[str, Any],
        documents: Optional[List[Dict[str, Any]]] = None,
        existing_records: Optional[List[Dict[str, Any]]] = None,
    ) -> Optional[Dict[str, Any]]:
        tender_id = tender.get("id")
        registry_type = tender.get("registry_type", "44fz")
        tender_name = tender.get("auction_name", f"–¢–æ—Ä–≥ #{tender_id}")
        folder_path: Path = tender.get("folder_path") or self._prepare_tender_folder(tender_id, registry_type)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∑–∞–ø–∏—Å–∏ –≤ –ë–î
        match_result = self._safe_tender_call(
            self.tender_match_repo.get_match_result,
            tender_id,
            registry_type,
        )
        
        # –ï—Å–ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É–∂–µ –µ—Å—Ç—å –≤ –ë–î, –ø—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ –ø–µ—Ä–µ–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å
        if match_result:
            processed_at = match_result.get("processed_at")
            match_count = match_result.get("match_count", 0)
            total_files = match_result.get("total_files_processed", 0)
            
            logger.info(
                f"–¢–æ—Ä–≥ {tender_id} ({registry_type}) —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω —Ä–∞–Ω–µ–µ: "
                f"–Ω–∞–π–¥–µ–Ω–æ {match_count} —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ {total_files} —Ñ–∞–π–ª–∞—Ö, "
                f"–æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_at if processed_at else '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'}"
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —Ñ–∞–π–ª—ã –Ω–∞ –¥–∏—Å–∫–µ
            if folder_path.exists() and any(folder_path.iterdir()):
                # –ï—Å–ª–∏ —Ñ–∞–π–ª—ã –µ—Å—Ç—å –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å–≤–µ–∂–∏–π, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É
                logger.info(
                    f"–ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–æ–≤—Ç–æ—Ä–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Ç–æ—Ä–≥–∞ {tender_id} ({registry_type}) - "
                    f"—Ä–µ–∑—É–ª—å—Ç–∞—Ç —É–∂–µ –µ—Å—Ç—å –≤ –ë–î –∏ —Ñ–∞–π–ª—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –Ω–∞ –¥–∏—Å–∫–µ. "
                    f"–î–ª—è –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–π –ø–µ—Ä–µ–æ–±—Ä–∞–±–æ—Ç–∫–∏ —É–¥–∞–ª–∏—Ç–µ –∑–∞–ø–∏—Å—å –∏–∑ –ë–î –∏–ª–∏ —Ñ–∞–π–ª—ã –∏–∑ –ø–∞–ø–∫–∏."
                )
                return {
                    "tender_id": tender_id,
                    "registry_type": registry_type,
                    "match_count": match_count,
                    "match_percentage": match_result.get("match_percentage", 0.0),
                    "skipped": True,
                    "reason": "already_processed"
                }
            else:
                # –ï—Å–ª–∏ —Ñ–∞–π–ª–æ–≤ –Ω–µ—Ç, –Ω–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –µ—Å—Ç—å - –≤–æ–∑–º–æ–∂–Ω–æ, —Ñ–∞–π–ª—ã –±—ã–ª–∏ —É–¥–∞–ª–µ–Ω—ã
                logger.info(
                    f"–†–µ–∑—É–ª—å—Ç–∞—Ç –µ—Å—Ç—å –≤ –ë–î, –Ω–æ —Ñ–∞–π–ª—ã –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç. "
                    f"–ë—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞."
                )
        
        # –í—Å–µ–≥–¥–∞ –æ—á–∏—â–∞–µ–º –ø–∞–ø–∫—É –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏, –µ—Å–ª–∏ –∑–∞–ø–∏—Å–∏ –Ω–µ—Ç –≤ –ë–î
        # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –æ—à–∏–±–∫–∏ –ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –æ—Ç–∫—Ä—ã—Ç—å –Ω–µ–ø–æ–ª–Ω—ã–µ —Ñ–∞–π–ª—ã –ø–æ—Å–ª–µ –ø—Ä–µ—Ä–≤–∞–Ω–Ω–æ–π –∑–∞–≥—Ä—É–∑–∫–∏
        if not match_result:
            logger.info(
                f"–ó–∞–ø–∏—Å–∏ –≤ –ë–î –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id} ({registry_type}) –Ω–µ—Ç. "
                f"–û—á–∏—â–∞–µ–º –ø–∞–ø–∫—É –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏."
            )
            self._clean_tender_folder_force(folder_path)
            # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º existing_records, –µ—Å–ª–∏ –∑–∞–ø–∏—Å–∏ –Ω–µ—Ç –≤ –ë–î
            existing_records = None

        if documents is None:
            documents = self._safe_tender_call(
                self.tender_provider.get_tender_documents,
                tender_id,
                registry_type,
            )

        download_records: List[Dict[str, Any]] = []
        if existing_records:
            logger.info(
                "–ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ —Å–∫–∞—á–∞–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–ª—è —Ç–æ—Ä–≥–∞ %s (%s): %s –∑–∞–ø–∏—Å–µ–π",
                tender_id,
                registry_type,
                len(existing_records),
            )
            download_records.extend(existing_records)

        if not download_records and documents:
            try:
                selected_docs = self.selector.choose_documents(documents)
                unique_docs = self.selector.group_documents_by_archive(selected_docs, documents)
                new_records = self._download_documents(unique_docs, documents, folder_path)
                download_records.extend(new_records)
            except DocumentSearchError as error:
                logger.warning(f"–î–ª—è —Ç–æ—Ä–≥–∞ {tender_id} –Ω–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö –ø–æ–¥ –∫—Ä–∏—Ç–µ—Ä–∏–∏: {error}")

        if not download_records:
            logger.warning(f"–ù–µ—Ç —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø–æ —Ç–æ—Ä–≥—É {tender_id}")
            return None

        logger.info(f"\n{'='*80}")
        logger.info(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–æ—Ä–≥–∞: {tender_name} (ID: {tender_id}, {registry_type})")
        logger.info(f"{'='*80}")

        processing_start = time.time()
        workbook_paths, archive_paths, excel_paths = self._prepare_workbook_paths(
            download_records,
            documents,
            folder_path,
        )
        if not workbook_paths:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å Excel —Ñ–∞–π–ª—ã –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id}")
            return None

        matches = self._search_matches(workbook_paths)
        processing_elapsed = time.time() - processing_start
        result = self._save_results(
            tender_id,
            registry_type,
            matches,
            workbook_paths,
            processing_elapsed,
        )

        # –û—á–∏—Å—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ - –æ—à–∏–±–∫–∏ –Ω–µ –ø—Ä–µ—Ä—ã–≤–∞—é—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ
        self.file_cleaner.cleanup_all_files(
            archive_paths,
            workbook_paths,
            extraction_success=True,
            db_save_success=result is not None,
        )

        return result

    def _download_documents(
        self,
        unique_docs: List[Dict[str, Any]],
        all_documents: List[Dict[str, Any]],
        tender_folder: Path,
    ) -> List[Dict[str, Any]]:
        records: List[Dict[str, Any]] = []
        if not unique_docs:
            return records

        with ThreadPoolExecutor(max_workers=min(self.max_workers, len(unique_docs))) as executor:
            future_to_doc = {
                executor.submit(
                    self.downloader.download_required_documents,
                    doc,
                    all_documents,
                    tender_folder,
                ): doc
                for doc in unique_docs
            }

            for future in as_completed(future_to_doc):
                doc = future_to_doc[future]
                try:
                    paths = future.result(timeout=300)
                except Exception as error:
                    logger.error(f"–û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è –¥–æ–∫—É–º–µ–Ω—Ç–∞ {doc.get('file_name')}: {error}")
                    continue
                if paths:
                    records.append(
                        {
                            "doc": doc,
                            "paths": paths,
                            "source": "download",
                            "retries": 0,
                        }
                    )
        return records

    def _prepare_workbook_paths(
        self,
        records: List[Dict[str, Any]],
        documents: Optional[List[Dict[str, Any]]],
        tender_folder: Path,
    ) -> tuple[List[Path], List[Path], List[Path]]:
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—É—Ç–µ–π –∫ Excel —Ñ–∞–π–ª–∞–º —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π.
        –£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã —Ñ–∞–π–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –ø–æ—è–≤–∏—Ç—å—Å—è –ø—Ä–∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∫–µ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —á–∞—Å—Ç–µ–π –∞—Ä—Ö–∏–≤–∞.
        –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏–¥–µ—Ç –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ + —Ä–∞–∑–º–µ—Ä, —á—Ç–æ–±—ã –∏—Å–∫–ª—é—á–∏—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–µ —Ñ–∞–π–ª—ã –∏–∑ —Ä–∞–∑–Ω—ã—Ö –ø–∞–ø–æ–∫.
        """
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å–ª–æ–≤–∞—Ä—å –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏: –∫–ª—é—á = (–∏–º—è_—Ñ–∞–π–ª–∞, —Ä–∞–∑–º–µ—Ä), –∑–Ω–∞—á–µ–Ω–∏–µ = –ø—É—Ç—å
        workbook_paths_dict: Dict[Tuple[str, int], Path] = {}
        workbook_paths_set: Set[Path] = set()  # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–π set –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ –ø—É—Ç–∏
        archive_paths: List[Path] = []
        queue: List[Dict[str, Any]] = [self._normalize_record(record) for record in records]
        duplicates_count = 0

        while queue:
            record = queue.pop(0)
            for file_path in record["paths"]:
                path = Path(file_path).resolve()  # –ò—Å–ø–æ–ª—å–∑—É–µ–º resolve() –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ –ø—É—Ç–∏
                if not path.exists():
                    continue
                suffix = path.suffix.lower()
                if suffix in self.ARCHIVE_EXTENSIONS:
                    archive_paths.append(path)
                    success = self._process_archive_path(
                        path,
                        record,
                        documents,
                        tender_folder,
                        queue,
                        workbook_paths_dict,  # –ü–µ—Ä–µ–¥–∞–µ–º dict –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
                        workbook_paths_set,   # –ò set –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
                    )
                    if not success:
                        logger.warning(f"–ê—Ä—Ö–∏–≤ {path.name} –ø—Ä–æ–ø—É—â–µ–Ω –∏–∑-–∑–∞ –æ—à–∏–±–æ–∫")
                elif suffix in self.EXCEL_EXTENSIONS:
                    if path.name.startswith("~$"):
                        continue
                    if self.extractor.is_file_archive(path):
                        logger.warning(f"–§–∞–π–ª {path.name} –≤—ã–≥–ª—è–¥–∏—Ç –∫–∞–∫ –∞—Ä—Ö–∏–≤, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                        continue
                    
                    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ + —Ä–∞–∑–º–µ—Ä
                    try:
                        file_size = path.stat().st_size
                        dedup_key = (path.name, file_size)
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ñ–∞–π–ª —Å —Ç–∞–∫–∏–º –∏–º–µ–Ω–µ–º –∏ —Ä–∞–∑–º–µ—Ä–æ–º
                        if dedup_key in workbook_paths_dict:
                            duplicates_count += 1
                            existing_path = workbook_paths_dict[dedup_key]
                            logger.debug(
                                "–ü—Ä–æ–ø—É—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–∞ —Ñ–∞–π–ª–∞: %s (—Ä–∞–∑–º–µ—Ä: %s –±–∞–π—Ç). "
                                "–£–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: %s",
                                path.name,
                                file_size,
                                existing_path
                            )
                        else:
                            workbook_paths_dict[dedup_key] = path
                            workbook_paths_set.add(path)
                    except OSError as error:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ {path}: {error}")
                        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä, –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ –ø—É—Ç–∏
                        if path not in workbook_paths_set:
                            workbook_paths_set.add(path)
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –∏–º—è –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏
                            dedup_key = (path.name, 0)
                            workbook_paths_dict[dedup_key] = path
                else:
                    logger.debug("–ü—Ä–æ–ø—É—Å–∫ –Ω–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–æ–≥–æ —Ñ–∞–π–ª–∞ %s", path.name)

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º dict –≤ list –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        workbook_paths = list(workbook_paths_dict.values())
        
        if duplicates_count > 0:
            logger.info(
                f"–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è —Ñ–∞–π–ª–æ–≤: –Ω–∞–π–¥–µ–Ω–æ {duplicates_count} –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ (–ø–æ –∏–º–µ–Ω–∏ –∏ —Ä–∞–∑–º–µ—Ä—É), "
                f"—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(workbook_paths)}"
            )
        else:
            logger.info(f"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö Excel —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {len(workbook_paths)}")

        return workbook_paths, archive_paths, workbook_paths.copy()

    def _process_archive_path(
        self,
        archive_path: Path,
        record: Dict[str, Any],
        documents: Optional[List[Dict[str, Any]]],
        tender_folder: Path,
        queue: List[Dict[str, Any]],
        workbook_paths_dict: Dict[Tuple[str, int], Path],  # Dict –¥–ª—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–∏ –ø–æ –∏–º–µ–Ω–∏+—Ä–∞–∑–º–µ—Ä
        workbook_paths_set: Set[Path],  # Set –¥–ª—è –±—ã—Å—Ç—Ä–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ –ø—É—Ç–∏
    ) -> bool:
        try:
            doc_meta = record.get("doc") or {}
            base_name, part_number = self.selector.split_archive_name(doc_meta.get("file_name") or archive_path.name)
            if part_number and part_number > 1:
                logger.debug(
                    "–ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ä–∞—Å–ø–∞–∫–æ–≤–∫—É —á–∞—Å—Ç–∏ %s (–æ–∂–∏–¥–∞–µ—Ç—Å—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ –≤–º–µ—Å—Ç–µ —Å –ø–µ—Ä–≤–æ–π —á–∞—Å—Ç—å—é)",
                    archive_path.name,
                )
                return True

            target_dir = self._resolve_extract_dir(record, tender_folder, archive_path, base_name)
            extracted_paths = self.extractor.extract_archive(archive_path, target_dir)
            if not extracted_paths:
                logger.warning(f"–ê—Ä—Ö–∏–≤ {archive_path.name} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç Excel —Ñ–∞–π–ª–æ–≤")
            else:
                # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞ + —Ä–∞–∑–º–µ—Ä
                new_files = 0
                duplicates = 0
                for extracted_path in extracted_paths:
                    path = Path(extracted_path).resolve()
                    if not path.exists():
                        continue
                    
                    try:
                        file_size = path.stat().st_size
                        dedup_key = (path.name, file_size)
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ —Ñ–∞–π–ª —Å —Ç–∞–∫–∏–º –∏–º–µ–Ω–µ–º –∏ —Ä–∞–∑–º–µ—Ä–æ–º
                        if dedup_key in workbook_paths_dict:
                            duplicates += 1
                            existing_path = workbook_paths_dict[dedup_key]
                            logger.debug(
                                "–ü—Ä–æ–ø—É—Å–∫ –¥—É–±–ª–∏–∫–∞—Ç–∞ –∏–∑ –∞—Ä—Ö–∏–≤–∞ %s: %s (—Ä–∞–∑–º–µ—Ä: %s –±–∞–π—Ç). "
                                "–£–∂–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è: %s",
                                archive_path.name,
                                path.name,
                                file_size,
                                existing_path
                            )
                        else:
                            workbook_paths_dict[dedup_key] = path
                            workbook_paths_set.add(path)
                            new_files += 1
                    except OSError as error:
                        logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ {path}: {error}")
                        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä, –¥–æ–±–∞–≤–ª—è–µ–º –ø–æ –ø—É—Ç–∏
                        if path not in workbook_paths_set:
                            workbook_paths_set.add(path)
                            dedup_key = (path.name, 0)
                            workbook_paths_dict[dedup_key] = path
                            new_files += 1
                
                logger.info(
                    f"–ê—Ä—Ö–∏–≤ {archive_path.name} —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω: –Ω–∞–π–¥–µ–Ω–æ —Ñ–∞–π–ª–æ–≤ {len(extracted_paths)}, "
                    f"–Ω–æ–≤—ã—Ö {new_files}, –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ {duplicates}"
                )
                record.setdefault("extracted", []).extend(extracted_paths)
            return True
        except Exception as error:
            logger.warning(f"–ê—Ä—Ö–∏–≤ {archive_path.name} –ø–æ–≤—Ä–µ–∂–¥–µ–Ω: {error}")
            self._remove_file(archive_path)
            doc_meta = record.get("doc")
            retries = record.get("retries", 0)
            if not doc_meta or retries >= 1 or not documents:
                logger.error(f"–ü–æ–≤—Ç–æ—Ä–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–ª—è {archive_path.name} –Ω–µ–≤–æ–∑–º–æ–∂–Ω–∞")
                return False
            try:
                new_paths = self.downloader.download_required_documents(doc_meta, documents, tender_folder)
                if new_paths:
                    queue.append(
                        {
                            "doc": doc_meta,
                            "paths": new_paths,
                            "source": "re-download",
                            "retries": retries + 1,
                        }
                    )
                    logger.info(f"–ê—Ä—Ö–∏–≤ {archive_path.name} –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω –ø–æ–≤—Ç–æ—Ä–Ω–æ")
            except Exception as retry_error:
                logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–≤—Ç–æ—Ä–Ω–æ —Å–∫–∞—á–∞—Ç—å –∞—Ä—Ö–∏–≤ {archive_path.name}: {retry_error}")
                return False
        return True

    def _resolve_extract_dir(
        self,
        record: Dict[str, Any],
        tender_folder: Path,
        archive_path: Path,
        base_name: Optional[str] = None,
    ) -> Path:
        doc_meta = record.get("doc") or {}
        file_name = doc_meta.get("file_name")
        if base_name is None and file_name:
            base_name, _ = self.selector.split_archive_name(file_name)
        if base_name:
            sanitized = base_name.replace("/", "_")
            return tender_folder / f"extract_{sanitized}"
        return tender_folder / f"extract_{archive_path.stem}"

    def _search_matches(self, workbook_paths: List[Path]) -> List[Dict[str, Any]]:
        """
        –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–π –ø–æ–∏—Å–∫ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –≤ Excel —Ñ–∞–π–ª–∞—Ö.
        –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ñ–∞–π–ª—ã –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ—Ç–æ–∫–∞—Ö –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è.
        """
        matches: Dict[str, Dict[str, Any]] = {}
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –Ω–∞ —Å–ª—É—á–∞–π, –µ—Å–ª–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã –≤—Å–µ –∂–µ –ø–æ–ø–∞–ª–∏
        unique_paths = list({Path(p).resolve() for p in workbook_paths})
        total_files = len(unique_paths)
        duplicates_removed = len(workbook_paths) - total_files
        
        if total_files == 0:
            return []
        
        if duplicates_removed > 0:
            logger.warning(
                "–û–±–Ω–∞—Ä—É–∂–µ–Ω–æ %s –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ —Å–ø–∏—Å–∫–µ —Ñ–∞–π–ª–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏, "
                "–±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤: %s",
                duplicates_removed,
                total_files
            )
        else:
            logger.info(f"–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {total_files} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤")
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º ThreadPoolExecutor –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ñ–∞–π–ª–æ–≤
        # –ö–∞–∂–¥—ã–π –ø–æ—Ç–æ–∫ —Å–æ–∑–¥–∞–µ—Ç —Å–≤–æ–π —ç–∫–∑–µ–º–ø–ª—è—Ä MatchFinder –¥–ª—è –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏
        max_workers = min(self.max_workers, total_files)
        
        def process_file(workbook_path: Path) -> Tuple[Path, List[Dict[str, Any]], Optional[Exception], float]:
            """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º –ø–æ—Ç–æ–∫–µ."""
            import time
            start_time = time.time()
            # –°–æ–∑–¥–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä MatchFinder –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ—Ç–æ–∫–∞
            # —Ç–∞–∫ –∫–∞–∫ openpyxl –Ω–µ –ø–æ—Ç–æ–∫–æ–±–µ–∑–æ–ø–∞—Å–µ–Ω
            thread_match_finder = MatchFinder(self.match_finder.product_names)
            try:
                file_matches = thread_match_finder.search_workbook_for_products(workbook_path)
                elapsed = time.time() - start_time
                return workbook_path, file_matches, None, elapsed
            except Exception as error:
                elapsed = time.time() - start_time
                return workbook_path, [], error, elapsed
        
        # –ü–æ–ª—É—á–∞–µ–º —Å—Ä–µ–¥–Ω—é—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑ –ë–î –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –≤—Ä–µ–º–µ–Ω–∏
        avg_time_per_file = self._get_average_processing_time_per_file()
        
        processed_count = 0
        failed_count = 0
        total_elapsed_time = 0.0
        start_time = time.time()
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            future_to_path = {
                executor.submit(process_file, workbook_path): workbook_path
                for workbook_path in unique_paths
            }
            
            for future in as_completed(future_to_path):
                workbook_path = future_to_path[future]
                processed_count += 1
                try:
                    # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
                    file_size_mb = 0
                    try:
                        file_size_mb = workbook_path.stat().st_size / (1024 * 1024)
                    except OSError:
                        pass
                    
                    # –ë–µ–∑ —Ç–∞–π–º–∞—É—Ç–∞ - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª –≤ –ª—é–±–æ–º —Å–ª—É—á–∞–µ
                    path, file_matches, error, elapsed_time = future.result()
                    total_elapsed_time += elapsed_time
                    
                    if error:
                        logger.error(
                            f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ –ø–æ —Ñ–∞–π–ª—É {workbook_path.name} "
                            f"(—Ä–∞–∑–º–µ—Ä: {file_size_mb:.2f} –ú–ë, –≤—Ä–µ–º—è: {elapsed_time:.1f} —Å–µ–∫): {error}"
                        )
                        failed_count += 1
                    else:
                        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ, –µ—Å–ª–∏ —Ñ–∞–π–ª –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª—Å—è —Å–ª–∏—à–∫–æ–º –¥–æ–ª–≥–æ
                        if elapsed_time > 120:  # –ë–æ–ª–µ–µ 2 –º–∏–Ω—É—Ç
                            logger.warning(
                                f"–§–∞–π–ª {workbook_path.name} –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–ª—Å—è –¥–æ–ª–≥–æ: {elapsed_time:.1f} —Å–µ–∫ "
                                f"(—Ä–∞–∑–º–µ—Ä: {file_size_mb:.2f} –ú–ë)"
                            )
                        
                        logger.info(
                            f"–ü–æ–∏—Å–∫ –ø–æ –¥–æ–∫—É–º–µ–Ω—Ç—É {workbook_path.name} ({processed_count}/{total_files}) - "
                            f"–Ω–∞–π–¥–µ–Ω–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(file_matches)}, –≤—Ä–µ–º—è: {elapsed_time:.1f} —Å–µ–∫, "
                            f"—Ä–∞–∑–º–µ—Ä: {file_size_mb:.2f} –ú–ë"
                        )
                        
                        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
                        for match in file_matches:
                            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è —Å –æ—Ü–µ–Ω–∫–æ–π >= 85 (100% –∏ 85%)
                            if match.get("score", 0) < 85.0:
                                continue
                            product_name = match.get("product_name")
                            existing = matches.get(product_name)
                            if not existing or existing.get("score", 0) < match.get("score", 0):
                                matches[product_name] = {**match, "source_file": str(workbook_path)}
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º –∏ –≤—ã–≤–æ–¥–∏–º –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è
                    remaining_files = total_files - processed_count
                    if remaining_files > 0:
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏, –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ, –∏–Ω–∞—á–µ —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤
                        if avg_time_per_file > 0:
                            estimated_time_per_file = avg_time_per_file
                        elif processed_count > 0:
                            estimated_time_per_file = total_elapsed_time / processed_count
                        else:
                            estimated_time_per_file = 10.0  # –î–µ—Ñ–æ–ª—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                        
                        # –£—á–∏—Ç—ã–≤–∞–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ—Å—Ç—å
                        estimated_time_per_file_adjusted = estimated_time_per_file / max_workers
                        estimated_remaining_seconds = remaining_files * estimated_time_per_file_adjusted
                        
                        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—Ä–µ–º—è
                        if estimated_remaining_seconds < 60:
                            time_str = f"{int(estimated_remaining_seconds)} —Å–µ–∫"
                        elif estimated_remaining_seconds < 3600:
                            minutes = int(estimated_remaining_seconds / 60)
                            seconds = int(estimated_remaining_seconds % 60)
                            time_str = f"{minutes} –º–∏–Ω {seconds} —Å–µ–∫"
                        else:
                            hours = int(estimated_remaining_seconds / 3600)
                            minutes = int((estimated_remaining_seconds % 3600) / 60)
                            time_str = f"{hours} —á {minutes} –º–∏–Ω"
                        
                        logger.info(
                            f"–ü—Ä–æ–≥—Ä–µ—Å—Å: –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ {processed_count}/{total_files} —Ñ–∞–π–ª–æ–≤, "
                            f"–æ—Å—Ç–∞–ª–æ—Å—å –ø—Ä–∏–º–µ—Ä–Ω–æ {time_str}"
                        )
                            
                except Exception as error:
                    failed_count += 1
                    logger.error(
                        f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {workbook_path.name}: {error}"
                    )
                    continue
        
        logger.info(
            f"–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: —É—Å–ø–µ—à–Ω–æ {processed_count - failed_count}/{total_files}, "
            f"–æ—à–∏–±–æ–∫ {failed_count}, –Ω–∞–π–¥–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(matches)}"
        )
        return list(matches.values())

    def _save_results(
        self,
        tender_id: int,
        registry_type: str,
        matches: List[Dict[str, Any]],
        workbook_paths: List[Path],
        processing_time: float,
    ) -> Optional[Dict[str, Any]]:
        exact_count = sum(1 for m in matches if m.get("score", 0) >= 100.0)
        good_count = sum(1 for m in matches if m.get("score", 0) >= 85.0)

        if exact_count > 0:
            match_percentage = 100.0
        elif good_count > 0:
            match_percentage = 85.0
        else:
            match_percentage = 0.0

        total_size = sum(path.stat().st_size for path in workbook_paths if path.exists())

        try:
            match_id = self._safe_tender_call(
                self.tender_match_repo.save_match_result,
                tender_id,
                registry_type,
                len(matches),
                match_percentage,
                processing_time,
                len(workbook_paths),
                total_size,
            )
            if not match_id:
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏—Ç–æ–≥–æ–≤—É—é –∑–∞–ø–∏—Å—å –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id}")
                return None

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–µ—Ç–∞–ª–∏ —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è
            # –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç —É–¥–∞–ª–µ–Ω–∏–µ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏—Ö –¥–µ—Ç–∞–ª–µ–π –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å –ø—É—Å—Ç—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
            if matches:
                self._safe_tender_call(
                    self.tender_match_repo.save_match_details,
                    match_id,
                    matches,
                )
            else:
                logger.debug(f"–ù–µ—Ç —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id}, –¥–µ—Ç–∞–ª–∏ –Ω–µ –æ–±–Ω–æ–≤–ª—è—é—Ç—Å—è (—Å–æ—Ö—Ä–∞–Ω—è—é—Ç—Å—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ)")

            logger.info(
                f"üíæ tender_document_matches <- {{tender_id={tender_id}, registry={registry_type}, "
                f"matches={len(matches)}, files={len(workbook_paths)}, "
                f"size={total_size / (1024 * 1024) if total_size else 0:.2f} –ú–ë}}"
            )
            logger.info(
                f"‚úÖ –¢–æ—Ä–≥ {tender_id} ({registry_type}) —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ –ë–î: "
                f"—Å–æ–≤–ø–∞–¥–µ–Ω–∏–π {len(matches)}, –ø—Ä–æ—Ü–µ–Ω—Ç {match_percentage} (match_id={match_id})"
            )
            return {
                "tender_id": tender_id,
                "registry_type": registry_type,
                "match_count": len(matches),
                "match_percentage": match_percentage,
            }
        except Exception as error:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è —Ç–æ—Ä–≥–∞ {tender_id}: {error}")
            logger.exception("–î–µ—Ç–∞–ª–∏ –æ—à–∏–±–∫–∏:")
            return None

    def _prepare_tender_folder(self, tender_id: int, registry_type: str) -> Path:
        folder_name = f"{registry_type}_{tender_id}"
        target_dir = self.download_dir / folder_name
        target_dir.mkdir(parents=True, exist_ok=True)
        return target_dir

    def _clean_tender_folder(self, folder_path: Path) -> None:
        """
        –û—á–∏—â–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ —Ç–µ–Ω–¥–µ—Ä–∞, –Ω–æ –Ω–µ —É–¥–∞–ª—è–µ—Ç —Å–∞–º—É –ø–∞–ø–∫—É.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–µ—Ä–µ–¥ –Ω–∞—á–∞–ª–æ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏, –µ—Å–ª–∏ –∑–∞–ø–∏—Å–∏ –Ω–µ—Ç –≤ –ë–î.
        """
        self._clean_tender_folder_force(folder_path)
    
    def _clean_tender_folder_force(self, folder_path: Path) -> None:
        """
        –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—á–∏—â–∞–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ —Ç–µ–Ω–¥–µ—Ä–∞, —É–±–∏–≤–∞—è –ø—Ä–æ—Ü–µ—Å—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –¥–µ—Ä–∂–∞—Ç —Ñ–∞–π–ª—ã.
        –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏ –ø–æ–≤—Ç–æ—Ä–Ω–æ–º –∑–∞–ø—É—Å–∫–µ –ø—Ä–æ–≥—Ä–∞–º–º—ã.
        """
        if not folder_path.exists() or not folder_path.is_dir():
            return
        
        logger.info(f"–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –æ—á–∏—Å—Ç–∫–∞ –ø–∞–ø–∫–∏ —Ç–µ–Ω–¥–µ—Ä–∞: {folder_path}")
        deleted_count = 0
        failed_items = []
        
        for item in folder_path.iterdir():
            try:
                if item.is_file():
                    self._remove_file_force(item)
                    deleted_count += 1
                elif item.is_dir():
                    # –†–µ–∫—É—Ä—Å–∏–≤–Ω–æ —É–¥–∞–ª—è–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –ø–æ–¥–ø–∞–ø–æ–∫
                    try:
                        shutil.rmtree(item, ignore_errors=True)
                        deleted_count += 1
                    except Exception:
                        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å –ø–∞–ø–∫—É, –ø—Ä–æ–±—É–µ–º –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª—ã –≤–Ω—É—Ç—Ä–∏
                        self._remove_directory_force(item)
                        try:
                            item.rmdir()
                            deleted_count += 1
                        except Exception:
                            failed_items.append(str(item))
            except Exception as error:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {item}: {error}")
                failed_items.append(str(item))
        
        if deleted_count > 0:
            logger.info(f"–£–¥–∞–ª–µ–Ω–æ —Ñ–∞–π–ª–æ–≤/–ø–∞–ø–æ–∫ –∏–∑ {folder_path}: {deleted_count}")
        if failed_items:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å {len(failed_items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤: {failed_items[:5]}")
    
    def _remove_directory_force(self, dir_path: Path) -> None:
        """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É–¥–∞–ª—è–µ—Ç –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏."""
        try:
            for item in dir_path.rglob('*'):
                if item.is_file():
                    self._remove_file_force(item)
                elif item.is_dir():
                    try:
                        item.rmdir()
                    except Exception:
                        pass
        except Exception as error:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–º —É–¥–∞–ª–µ–Ω–∏–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {dir_path}: {error}")
    
    def _remove_file_force(self, path: Path) -> None:
        """
        –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª, —É–±–∏–≤–∞—è –ø—Ä–æ—Ü–µ—Å—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –µ–≥–æ –¥–µ—Ä–∂–∞—Ç (—Ç–æ–ª—å–∫–æ –Ω–∞ Windows).
        """
        if not path.exists():
            return
        
        import sys
        import subprocess
        
        # –ü—Ä–æ–±—É–µ–º –æ–±—ã—á–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ
        try:
            path.unlink()
            return
        except (OSError, PermissionError) as error:
            error_code = getattr(error, 'winerror', None) or getattr(error, 'errno', None)
            
            # WinError 32 = —Ñ–∞–π–ª –∑–∞–Ω—è—Ç –¥—Ä—É–≥–∏–º –ø—Ä–æ—Ü–µ—Å—Å–æ–º
            if sys.platform == 'win32' and error_code == 32:
                try:
                    # –ù–∞ Windows –∏—Å–ø–æ–ª—å–∑—É–µ–º handle.exe –∏–ª–∏ PowerShell –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏ —É–±–∏–π—Å—Ç–≤–∞ –ø—Ä–æ—Ü–µ—Å—Å–∞
                    # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ–º —á–µ—Ä–µ–∑ PowerShell
                    ps_command = f'''
                    $file = "{path}"; 
                    $processes = Get-Process | Where-Object {{$_.Path -eq $file -or (Get-Process -Id $_.Id).Modules.FileName -like "*$file*"}};
                    if ($processes) {{ $processes | Stop-Process -Force }}
                    '''
                    
                    subprocess.run(
                        ['powershell', '-Command', ps_command],
                        capture_output=True,
                        timeout=5,
                        check=False
                    )
                    
                    # –ñ–¥–µ–º –Ω–µ–º–Ω–æ–≥–æ –∏ –ø—Ä–æ–±—É–µ–º —Å–Ω–æ–≤–∞
                    import time
                    time.sleep(0.5)
                    
                    try:
                        path.unlink()
                        logger.debug(f"–§–∞–π–ª {path.name} —É–¥–∞–ª–µ–Ω –ø–æ—Å–ª–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞")
                        return
                    except Exception:
                        pass
                except Exception as ps_error:
                    logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≤–µ—Ä—à–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å —á–µ—Ä–µ–∑ PowerShell: {ps_error}")
            
            # –ï—Å–ª–∏ –Ω–µ –ø–æ–º–æ–≥–ª–æ, –ø—Ä–æ–±—É–µ–º –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å –∏ —É–¥–∞–ª–∏—Ç—å –ø–æ–∑–∂–µ
            try:
                temp_path = path.with_suffix(path.suffix + '.tmp_delete')
                if temp_path.exists():
                    temp_path.unlink()
                path.rename(temp_path)
                logger.debug(f"–§–∞–π–ª {path.name} –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ —É–¥–∞–ª–µ–Ω–∏—è")
            except Exception:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª {path.name}")

    def _reset_tender_folder(self, folder_path: Path) -> None:
        """–ü–æ–ª–Ω–æ—Å—Ç—å—é —É–¥–∞–ª—è–µ—Ç –ø–∞–ø–∫—É —Ç–æ—Ä–≥–∞ –∏ —Å–æ–∑–¥–∞–µ—Ç –∑–∞–Ω–æ–≤–æ."""
        try:
            if folder_path.exists():
                shutil.rmtree(folder_path, ignore_errors=False)
        except Exception as error:
            logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª–Ω–æ—Å—Ç—å—é —É–¥–∞–ª–∏—Ç—å –ø–∞–ø–∫—É {folder_path}: {error}")
        folder_path.mkdir(parents=True, exist_ok=True)


    def _normalize_record(self, record: Dict[str, Any]) -> Dict[str, Any]:
        normalized = dict(record)
        normalized["paths"] = [Path(p) for p in record.get("paths", [])]
        normalized["retries"] = record.get("retries", 0)
        return normalized

    def _remove_file(self, path: Path, max_retries: int = 3, retry_delay: float = 2.0) -> None:
        """
        –£–¥–∞–ª—è–µ—Ç —Ñ–∞–π–ª —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –∏ —Ç–∞–π–º–∞—É—Ç–æ–º.
        
        Args:
            path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è
            max_retries: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫
            retry_delay: –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –ø–æ–ø—ã—Ç–∫–∞–º–∏ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö
        """
        if not path.exists():
            return
        
        import time
        import os
        
        last_error = None
        for attempt in range(1, max_retries + 1):
            try:
                # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–∫—Ä—ã—Ç—å —Ñ–∞–π–ª, –µ—Å–ª–∏ –æ–Ω –æ—Ç–∫—Ä—ã—Ç
                try:
                    if path.is_file():
                        # –ù–∞ Windows –∏–Ω–æ–≥–¥–∞ –ø–æ–º–æ–≥–∞–µ—Ç –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –ø–µ—Ä–µ–¥ —É–¥–∞–ª–µ–Ω–∏–µ–º
                        temp_path = path.with_suffix(path.suffix + '.tmp')
                        if temp_path.exists():
                            temp_path.unlink()
                        path.rename(temp_path)
                        temp_path.unlink()
                    else:
                        path.unlink()
                except (OSError, PermissionError):
                    # –ï—Å–ª–∏ –ø–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ –Ω–µ –ø–æ–º–æ–≥–ª–æ, –ø—Ä–æ–±—É–µ–º –æ–±—ã—á–Ω–æ–µ —É–¥–∞–ª–µ–Ω–∏–µ
                    path.unlink()
                
                logger.debug(f"–£–¥–∞–ª–µ–Ω —Ñ–∞–π–ª: {path}")
                return
                
            except (OSError, PermissionError) as error:
                last_error = error
                error_code = getattr(error, 'winerror', None) or getattr(error, 'errno', None)
                
                # WinError 32 = —Ñ–∞–π–ª –∑–∞–Ω—è—Ç –¥—Ä—É–≥–∏–º –ø—Ä–æ—Ü–µ—Å—Å–æ–º
                # errno 13 = Permission denied
                if error_code in (32, 13) and attempt < max_retries:
                    logger.debug(
                        f"–§–∞–π–ª {path.name} –∑–∞–Ω—è—Ç –¥—Ä—É–≥–∏–º –ø—Ä–æ—Ü–µ—Å—Å–æ–º. "
                        f"–ü–æ–ø—ã—Ç–∫–∞ {attempt}/{max_retries}, –ø–æ–≤—Ç–æ—Ä —á–µ—Ä–µ–∑ {retry_delay} —Å–µ–∫..."
                    )
                    time.sleep(retry_delay)
                    continue
                else:
                    break
            except Exception as error:
                last_error = error
                break
        
        # –ï—Å–ª–∏ –≤—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –Ω–µ —É–¥–∞–ª–∏—Å—å, –ª–æ–≥–∏—Ä—É–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ
        logger.warning(
            f"–ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª {path.name} –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫: {last_error}. "
            f"–§–∞–π–ª –±—É–¥–µ—Ç —É–¥–∞–ª–µ–Ω –ø–æ–∑–∂–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏."
        )

    def _safe_tender_call(self, func, *args, **kwargs):
        while True:
            try:
                self._ensure_tender_connection()
                return func(*args, **kwargs)
            except DatabaseConnectionError as error:
                self._handle_db_disconnect(error)

    def _ensure_tender_connection(self):
        if self.tender_db_manager.is_connected():
            return
        self._attempt_connect()

    def _attempt_connect(self):
        try:
            self.tender_db_manager.connect()
        except DatabaseConnectionError as error:
            self._handle_db_disconnect(error)

    def _get_average_processing_time_per_file(self) -> float:
        """
        –ü–æ–ª—É—á–∞–µ—Ç —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏ –ë–î.
        
        Returns:
            –°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –≤ —Å–µ–∫—É–Ω–¥–∞—Ö, –∏–ª–∏ 0.0 –µ—Å–ª–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç
        """
        try:
            from psycopg2.extras import RealDictCursor
            query = """
                SELECT 
                    AVG(processing_time_seconds / NULLIF(total_files_processed, 0)) as avg_time_per_file
                FROM tender_document_matches
                WHERE processing_time_seconds IS NOT NULL 
                    AND total_files_processed > 0
                    AND processing_time_seconds > 0
            """
            results = self.tender_db_manager.execute_query(query, None, RealDictCursor)
            if results and results[0].get('avg_time_per_file'):
                avg_time = float(results[0]['avg_time_per_file'])
                logger.debug(f"–°—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏: {avg_time:.2f} —Å–µ–∫")
                return avg_time
        except Exception as error:
            logger.debug(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑ –ë–î: {error}")
        
        return 0.0
    
    def _handle_db_disconnect(self, error: Exception):
        logger.error("–ü–æ—Ç–µ—Ä—è–Ω–æ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î tender_monitor: %s", error)
        try:
            self.tender_db_manager.disconnect()
        except Exception:
            pass

        while True:
            logger.info("–ü–æ–≤—Ç–æ—Ä–Ω–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î —á–µ—Ä–µ–∑ %s —Å–µ–∫—É–Ω–¥...", self._reconnect_delay)
            time.sleep(self._reconnect_delay)
            try:
                self.tender_db_manager.connect()
                logger.info("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –ë–î tender_monitor –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
                break
            except DatabaseConnectionError as reconnect_error:
                logger.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ –ë–î tender_monitor: %s", reconnect_error)
                continue

